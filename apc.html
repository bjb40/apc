<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Approximating Age-Period-Cohort Estimates by Averaging Multiple Models with Varying Window Restrictions</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<div id="header">
<h1 class="title">Approximating Age-Period-Cohort Estimates by Averaging Multiple Models with Varying Window Restrictions</h1>
<h2 class="author">true</h2>
<h2 class="author">true</h2>
</div>
<h1 id="abstract">Abstract</h1>
<p>Key words: Computational Sociology, Methods, Life Course, Bayesian, Culture</p>
<h1 id="introduction">Introduction</h1>
<h1 id="background">Background</h1>
<p>Both classic and modern studies have proposed different effects across three social dimensions of time: age, period, and cohort <span class="citation">(Ryder 1965)</span>. These dimensions of time operate on individuals in different ways as they flow through social space. Age effects are driven either by the common experiences associated with the biological process of aging <span class="citation">(Jackson, Weale, and Weale 2003)</span>, or persistent age-structuring institutions, like high school or retirement <span class="citation">(Leisering 2003; Moen 2014)</span>. Period effects are responses of everyone to contemporaneous social experiences, like recessions or wars <span class="citation">(Lam, Fan, and Moen 2014)</span>. Finally, cohort effects are socialization effects. They are broad-based historical events that stick to the populations experiencing them, even after the event has long since ended <span class="citation">(Vaisey and Lizardo 2016)</span>. In contemporary research, cohorts are virtually always defined in terms of birth year.</p>
<p>These three dimensions of time sit at the center of some recurrent debates. For example, cultural sociologists are divided over whether the main driver of culture is a period process (cultural fragmentation) or a cohort process (acquired dispositions) <span class="citation">(Vaisey and Lizardo 2016)</span>. Clinical reasearchers and biodemographers are looking for biological age—indicators of biological deterioration—but argue about confounding from cohort changes <span class="citation">(Jackson et al. 2003)</span>. And yet others are concerned about separating long-term and short-term impacts of important events, like the Great Recession <span class="citation">(Burgard and Kalousova 2015)</span>.</p>
<p>Unfortunately, it is not trivial to estimate the unique effects of age, period, and cohort to find evidence that may settle these questions and debates. The fundamental problem is one of statistical identification: these three dimensions are linearly dependent. Two of the dimensions define the third. If a researcher knows an individual’s age, and the year of the survey, cohort is also defined. Because these variables are exactly colinear, they are not estimable using classic statistical techniques. A number of solutions have been proposed to address this conundrum, these include traditional methods like block/window constraints <span class="citation">(Anon. 2005)</span>, and new methods, including statistical transformation (the “intrinsic estimator”), and random effects models <span class="citation">(Yang and Land 2013)</span>.</p>
<p>The past several years have seen a resurgence in debates surrounding these issues <span class="citation">(Bell and Jones 2017; Luo 2013; Luo and Hodges 2016)</span>. Perhaps the most common argument is that the “constraints”, <em>i.e.</em> assumptions used to break the APC identity, produce unknown biases into the models. In reality, this presents an extreme case of multicollinearity, a well-known, though difficult problem in statistical theory <span class="citation">(Wooldridge 2009, at p. 95-98)</span>, with numerous cautions in applied texts that separating highly colinear effects is difficult <span class="citation">(Camm 2016, at p. 328)</span>. From a Bayesian perspective, collinearity and multicollinearity significantly reduce the ability of the data to supply information to produce the estimates, potentially introducing sensitivity to the prior <span class="citation">(Gelman 2014, at p. 305-306)</span>, including assumtpions of linearity. To put it another way, the critique of APC models in general, and window constraints in particular <span class="citation">(Luo and Hodges 2016)</span>, is that different sets of assumptions lead to different (and inconsistent) results. But, what if Instead of focusing on finding a <em>best</em> fitting model, we use a simple nonlinear approach (block modelling), and hundreds of assumptions? BMA allows us to do just that: run hundreds of models with differeing assumptions, and then combine them, weighted by their fit with the data.</p>
<h1 id="bayesian-model-averaging">Bayesian Model Averaging</h1>
<p>The theoretical backdrop of BMA applies to this curcumstance quite well. In principal, there is no one true (or best) model; instead estimates are conditional on models from the modeling space (<span class="math inline">\(\mathscr{M}\)</span>), and have a posterior distribution, which is calculated as a weighted average of all models <span class="citation">(Raftery 1995:144–45)</span>. It has been applied in diverse areas from weather forecasting to biology to social science <span class="citation">(Fragoso and Neto 2015)</span> . BMA operates under the simple fact that any particular estimate, including effect size and significance, have a posterior probability distribution which is calculated as “an average of the posterior distributions under each of the models considered, weighted by their posterior model probability.” <span class="citation">(Hoeting et al. 1999)</span>. The major difficulties for BMA are (1) how to sample models to test, and (2) how to calculate the posterior model probability given the data (or <span class="math inline">\(p(M|D)\)</span> where <span class="math inline">\(M\)</span> is the model, and <span class="math inline">\(D\)</span> is the data). For model selection, we use the Markov Chain Monte Carlo Composition (MC3) method. We use the Bayesian Information Crieterion (BIC) approximation. To implement the MC3 method, we use the following steps:</p>
<ol style="list-style-type: decimal">
<li>Define a jumping distribution <span class="math inline">\(g(.)\)</span>, so that <span class="math inline">\(g(M \rightarrow M&#39;)\)</span> is non-zero for all possible window constraints.</li>
<li>Specify a starting model, <span class="math inline">\(M\)</span>, and ellicit priors for models <span class="math inline">\(M\)</span> in <span class="math inline">\(\mathscr{M}\)</span>.</li>
<li>Given that the chain is in state <span class="math inline">\(M\)</span>, draw <span class="math inline">\(M&#39;\)</span>, and accept it with probability</li>
</ol>
<p><span class="math display">\[
min  \Bigg \{ 1, \frac{p(M&#39;|D)}{p(M|D)} \Bigg \} 
\]</span></p>
<p>otherwise, retain <span class="math inline">\(M\)</span>.</p>
<h2 id="step-one-defining-a-window-constraint-sampler">Step One: Defining a Window Constraint Sampler</h2>
<p>In terms of window constraints, the target model, which is inestimable, is built by estimating each unique value of age, period, and cohort, as a dummy variable series:</p>
<p><span class="math display">\[
E(Y) = \beta_{00} + \sum_{\lambda=2}^{\lambda} \beta_{1\lambda}A_{\lambda} +  \sum_{\rho=2}^{\rho} \beta_{2\rho}P_{\rho} +  \sum_{\kappa=2}^{\kappa} \beta_{3\kappa}C_{\kappa}
\]</span></p>
<p>where <span class="math inline">\(\beta\)</span> is an estimated effect, <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\rho\)</span> and <span class="math inline">\(\kappa\)</span> index unique values for age, period, and cohort, and <span class="math inline">\(A\)</span>, <span class="math inline">\(P\)</span>, and <span class="math inline">\(C\)</span> stand for matricies of dummy variable series for age, period, and cohort. This model is unidentified, because, as with the continuous case, the dummy variables in any two of the matricies above fully condition the third matrix. In other words, the indicator variable in <span class="math inline">\(C\)</span> is a function of the indicators in <span class="math inline">\(A\)</span> and <span class="math inline">\(P\)</span> (in mathematical terms,the probability that any given cohort dummy variable is one or zero is exctly dependent on the values of A and P, so that <span class="math inline">\(p(C_{\kappa}=0|A_{\lambda},P_{\kappa}\)</span>) is always exaclty zero, or exactly one, depending on the values of <span class="math inline">\(A\)</span> and <span class="math inline">\(P\)</span>).</p>
<p>We can break this dependencey, however, by transofrming <span class="math inline">\(A\)</span>, <span class="math inline">\(P\)</span>, and <span class="math inline">\(C\)</span>—preferably without resulting to some prespecified arbitrary set of constraints <span class="citation">(Gelman 2014, at p. 366)</span>. How do the window constraints break the linear dependency? By way of example, we can construct an age dummy variable series where <span class="math inline">\(A\)</span> is sliced into two groups based on some cut-point so that, for example, individuals who are older than 30 have a dummy variable of 1 and the dummy variable for those 30 or younger euqls 0. This would identify a binary dummy variable with an older and a younger group. We can generalize this expression to an arbitrary vector of cut-points, <span class="math inline">\(G\)</span> with subscript <span class="math inline">\(\gamma\)</span> so that the window constraints of <span class="math inline">\(A\)</span> in equation __ are as follows:</p>
<p><span class="math display">\[
\mbox{for} \gamma &lt; max(\gamma):
A_{\lambda}  =
\begin{cases}
  1, &amp; \mbox{if} &amp; a &gt; G_{\gamma} &amp; \mbox{and} &amp; a \leq G_{\gamma+1} \\
  0, &amp; \mbox{if} &amp; a &lt; G_{\gamma} &amp; \mbox{or} &amp; a &gt; G_{\gamma+1}
\end{cases}
\]</span></p>
<p>If the vector <span class="math inline">\(G\)</span> and <span class="math inline">\(\gamma\)</span> have the following properties: <span class="math inline">\(max(G) = max(a)\)</span>, <span class="math inline">\(min(G) &lt; min(a)\)</span>, <span class="math inline">\(G_2 \geq min(a)\)</span> and <span class="math inline">\(\gamma&gt;2\)</span>, then <span class="math inline">\(G\)</span> can describe any posible sets of window restrictions for age. The first three requirement ensures that the dummy variable series <span class="math inline">\(A\)</span> is fully defined across the entire range of the continuous variable <span class="math inline">\(a\)</span>. In particular, the first restriction ensures that the dummy variable series with the oldest ages in <span class="math inline">\(G\)</span> contains the maximum value of <span class="math inline">\(a\)</span>. Similarly, the next two restrictins ensure that the smallest window constraint in <span class="math inline">\(G\)</span> contains the minimum value of <span class="math inline">\(a\)</span>. The final constraint requires that <span class="math inline">\(G\)</span> have at least three elements. Three elements in <span class="math inline">\(G\)</span> defines a dummy variable. Using the example above, if <span class="math inline">\(a\)</span> has a range of 5 to 50, then the dummy variale distinguishing older and younger respondents can be defined by <span class="math inline">\(G \in \{4,30,50\}\)</span>.</p>
<p>Generalizing cross all dimensions of APC, permuting three similar vectors (say <span class="math inline">\(G^{(d)}\)</span>) will describe any model for any possible window constraints detailed in equation 1. Accordingly, all permutations of G, as defined above, constitute the model space of window constraints (<span class="math inline">\(\mathscr{M}\)</span>). For any given set of APC variables, <span class="math inline">\(\mathscr{M}\)</span> is finite, but it can become large. For example, 5 unique ages, periods, and cohorts allow for 3,375 unique window models<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, and 6 unique values for each of age, period, and cohort allow for 38,304 different models. In any model space, only 1 model is inestimable because of perfect colinearity. This target model is (theoretially) the least biased, although it is almost certainly the most parsimonious. The question is how to best use information from some subset of possible models in <span class="math inline">\(\mathscr{M}\)</span> to estimate unbiased APC effects of the target model. Bayesian Model Averaging (BMA) provides a straightforward way to combine models.</p>
<p>There are two features of <span class="math inline">\(G\)</span> that make the MC3 algorithm provides an attractive way to sample models. <span class="math inline">\(G\)</span> can be decomposed into two parts: (1) the number of windows, and (2) the break points for each of the windows. By disaggregating <span class="math inline">\(G\)</span> into these two parts, we use the Dirchelet distribution as the jumping distribution to construct matrix <span class="math inline">\(G\)</span> to define models.</p>
<p><em>Using the Dirichlet Distribution to Sample Window Groups (G).</em> As noted above, there are two basic features of vector <span class="math inline">\(G\)</span>. First, is the number of window breaks, or the rank of <span class="math inline">\(G\)</span>, and second is the location of the window breaks, or the values of <span class="math inline">\(G\)</span>. We use a uniform distribution over the range of A,P, or C to sample the number of window breaks. This is simple, straightforward, and noninformative. We use the Dirichelet distributon to sample the location of window breaks. The Dirichelet is well-suited to this task, and is commonly used in classification tasks <code>citation</code>. In additon, Taddy et al. <span class="citation">(2015)</span> show that the Dirichelet is a natural prior distribution for variable selection and value-splitting in classification and regression trees (CART) algortithms, common for machine learning. Our approach is a similar, as developing <span class="math inline">\(G\)</span> is fundamentally a classificaiton task which aggregates similar ages, periods, and cohorts.</p>
<p>To implement our sampling scheme, we draw two sets of auxiliary variables for each dimension (<span class="math inline">\(d\)</span>) of APC.</p>
<p>the window breaks, <span class="math inline">\(G^{(d)}\)</span> of equation 2 are decomposed into (1) a simplex for each dimension, with the same length of unique elements in <span class="math inline">\(d\)</span> (<span class="math inline">\(B^{(d)}\)</span>), and (2) a scalar integer, <span class="math inline">\(w^d\)</span>. <span class="math inline">\(G^{(d)}\)</span> is simply the product of <span class="math inline">\(B\)</span> times <span class="math inline">\(w\)</span>. We use a uniform distribution to sample <span class="math inline">\(w\)</span>, and a Dirchelet distribution to sample from the simplex as follows:</p>
<p><span class="math display">\[
\begin{matrix}
G^{(d)}_b = \Bigg \lfloor w^{(d)} \sum_{i=1}^{\tau_d} B^{(d)}_i \Bigg \rfloor,
      \mbox{where} G_b &gt; G_{b-1} \mbox{and} b \subseteq \tau_d   \\
w^{(d)} \sim U(2,max(T^{(d)}))  \\
B^{(d)} \sim Dir(\alpha_{\tau_d}) \\
\end{matrix}
\]</span></p>
<p>Where <span class="math inline">\(\tau_{d}\)</span> is the index number for the APC effects (the <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\rho\)</span>, or <span class="math inline">\(\kappa\)</span> of equaiton 1) <span class="math inline">\(T\)</span> is the continuous vector of values (the <span class="math inline">\(A\)</span>,<span class="math inline">\(P\)</span>, or <span class="math inline">\(C\)</span>). <code>add explanation</code></p>
<p><em>Priors and Initial Model</em> The <span class="math inline">\(\alpha\)</span> for the Dirichelet distribution are for each of the vunique values in the dimension (<span class="math inline">\(d\)</span>) for APC. The Dirchelet distribution draws a random projection on the standard simplex, <em>i.e.</em> a vector of weights <span class="math inline">\(B\)</span> weights between 0 and 1 which sum to 1. Multiplying the vector of weights (<span class="math inline">\(B\)</span>) by a scalar <span class="math inline">\(w\)</span> provides a set of numbers which sum to the scalar value <span class="math inline">\(w^{(d)}\)</span>. We transform <span class="math inline">\(B\)</span> and <span class="math inline">\(w\)</span> into matrix <span class="math inline">\(G\)</span> by selecting the unique floor rounded values of the product of the cumulative sums of <span class="math inline">\(B\)</span>:</p>
<p>Where <span class="math inline">\(G\)</span> is a vector of the type described in equation 2, and <span class="math inline">\(d\)</span> indexes <span class="math inline">\(G\)</span> and is a subset of the unique values in <span class="math inline">\(T\)</span>.</p>
<h1 id="a-simulation">A Simulation</h1>
<h1 id="an-empirical-example-from-the-gss">An Empirical Example from the GSS</h1>
<h1 id="discussion">Discussion</h1>
<h1 id="conclusion" class="references unnumbered">Conclusion</h1>
<div id="ref-glenn_strategies_2005">
<p>Anon. 2005. “Strategies for Estimating Age, Period, and Cohort Effects.” Pp. 12–35 in <em>Cohort analysis</em>. 2455 Teller Road,?Thousand Oaks?California?91320?United States of America? SAGE Publications, Inc.</p>
</div>
<div id="ref-bell_hierarchical_2017">
<p>Bell, Andrew and Kelvyn Jones. 2017. “The Hierarchical Age-Period-Cohort Model: Why Does It Find the Results That It Finds?” <em>Quality &amp; Quantity</em>.</p>
</div>
<div id="ref-burgard_effects_2015">
<p>Burgard, Sarah A. and Lucie Kalousova. 2015. “Effects of the Great Recession: Health and Well-Being.” <em>Annual Review of Sociology</em> 41(1):181–201.</p>
</div>
<div id="ref-camm_essentials_2016">
<p>Camm, Jeffrey D. 2016. <em>Essentials of Business Analytics</em>. Mason, OH: Cengage South western.</p>
</div>
<div id="ref-fragoso_bayesian_2015">
<p>Fragoso, Tiago M. and Francisco Louzada Neto. 2015. “Bayesian Model Averaging: A Systematic Review and Conceptual Classification.” <em>arXiv preprint arXiv:1509.08864</em>.</p>
</div>
<div id="ref-gelman_bayesian_2014">
<p>Gelman, Andrew. 2014. <em>Bayesian Data Analysis</em>. Third edition. Boca Raton: CRC Press.</p>
</div>
<div id="ref-hoeting_bayesian_1999">
<p>Hoeting, Jennifer A., David Madigan, Adrian E. Raftery, and Chris T. Volinsky. 1999. “Bayesian Model Averaging: A Tutorial.” <em>Statistical science</em> 382–401.</p>
</div>
<div id="ref-jackson_biological_2003">
<p>Jackson, Stephen HD, Martin R. Weale, and Robert A. Weale. 2003. “Biological Age—what Is It and Can It Be Measured?” <em>Archives of gerontology and geriatrics</em> 36(2):103–15.</p>
</div>
<div id="ref-lam_is_2014">
<p>Lam, Jack, Wen Fan, and Phyllis Moen. 2014. “Is Insecurity Worse for Well-Being in Turbulent Times? Mental Health in Context.” <em>Society and Mental Health</em> 4(1):55–73.</p>
</div>
<div id="ref-mortimer_government_2003">
<p>Leisering, Lutz. 2003. “Government and the Life Course.” Pp. 205–25 in <em>Handbook of the life course</em>, edited by Jeylan T. Mortimer and Michael J. Shanahan. New York: Kluwer Academic/Plenum Publishers,</p>
</div>
<div id="ref-luo_assessing_2013">
<p>Luo, Liying. 2013. “Assessing Validity and Application Scope of the Intrinsic Estimator Approach to the Age-Period-Cohort Problem.” <em>Demography</em> 50(6):1945–67.</p>
</div>
<div id="ref-luo_block_2016">
<p>Luo, Liying and James S. Hodges. 2016. “Block Constraints in Age–Period–Cohort Models with Unequal-Width Intervals.” <em>Sociological Methods &amp; Research</em> 45(4):700–726.</p>
</div>
<div id="ref-waite_constrained_2014">
<p>Moen, Phyllis. 2014. “Constrained Choices: The Shifting Institutional Contexts of Aging and the Life Course.” Pp. 175–216 in <em>New directions in the sociology of aging</em>, edited by Linda J. Waite, Thomas J. Plewes, and National Research Council (U.S.). Washington, D.C: National Academies Press.</p>
</div>
<div id="ref-raftery_bayesian_1995">
<p>Raftery, Adrian E. 1995. “Bayesian Model Selection in Social Research.” <em>Sociological Methodology</em> 25:111–63.</p>
</div>
<div id="ref-ryder_cohort_1965">
<p>Ryder, Norman B. 1965. “The Cohort as a Concept in the Study of Social Change.” <em>American Sociological Review</em> 30(6):843–61.</p>
</div>
<div id="ref-taddy_bayesian_2015">
<p>Taddy, Matt, Chun-Sheng Chen, Jun Yu, and Mitch Wyle. 2015. “Bayesian and Empirical Bayesian Forests.” <em>arXiv preprint arXiv:1502.02312</em>.</p>
</div>
<div id="ref-vaisey_cultural_2016">
<p>Vaisey, Stephen and Omar Lizardo. 2016. “Cultural Fragmentation or Acquired Dispositions? A New Approach to Accounting for Patterns of Cultural Change.” <em>Socius: Sociological Research for a Dynamic World</em> 2:2378023116669726.</p>
</div>
<div id="ref-wooldridge_introductory_2009">
<p>Wooldridge, Jeffrey M. 2009. <em>Introductory Econometrics: A Modern Approach</em>. 4th ed. Mason, OH: South Western, Cengage Learning.</p>
</div>
<div id="ref-yang_age-period-cohort_2013">
<p>Yang, Yang and Kenneth C. Land. 2013. <em>Age-Period-Cohort Analysis: New Models, Methods, and Empirical Applications</em>. Boca Raton, FL: CRC Press.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>A continuous variable of 5 integers can be sliced into continous window constraints in 15 ways (where | indicates a window break for dummy variables):</p>
<p>2 windows, 4 combinations: 1|2345, 12|345, 123|45, 1234|5</p>
<p>3 windows, 6 combinations: 1|2|345, 1|23|45, 1|234|5, 12|3|45, 12|34|5, 123|4|5</p>
<p>4 windows, 4 combinations: 1|2|3|45, 1|2|34|5, 1|23|4|5, 12|3|4|5</p>
<p>5 windows, 1 combination: 1|2|3|4|5</p>
<p>Since the hypothetical assumes 3 variables (A,P,and C) of 15 combinations each, total combinations are <span class="math inline">\(15^3=3,375\)</span>. Similar calculations over an integer of 6 leads to 34 window combinations over each dimension for a total of 39,304 possible models.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
</body>
</html>
